{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "zeQOHsYkBCwx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torch import tanh, exp\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-XjhuYKBIj8",
    "outputId": "d3ab2132-5f32-45d1-9d6c-17b90212cc4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]]\n",
      "\n",
      " [[ 9 10 11]\n",
      "  [12 13 14]\n",
      "  [15 16 17]]\n",
      "\n",
      " [[18 19 20]\n",
      "  [21 22 23]\n",
      "  [24 25 26]]] \n",
      "\n",
      "manually compute sum() on the first dimension:\n",
      "[[27. 30. 33.]\n",
      " [36. 39. 42.]\n",
      " [45. 48. 51.]]\n",
      "\n",
      "torch.sum(,0):\n",
      "[[27 30 33]\n",
      " [36 39 42]\n",
      " [45 48 51]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  sum on the first dim, not keeping dimensionality\n",
    "#\n",
    "\n",
    "aa = torch.tensor(range(27)).reshape(3,3,3)\n",
    "ss = torch.zeros(3,3)\n",
    "print(aa.numpy(),'\\n')\n",
    "for j in range(3):\n",
    "    for k in range(3):\n",
    "        ss[j,k] = torch.sum(aa[:, j, k])\n",
    "print(f\"manually compute sum() on the first dimension:\\n{ss.numpy()}\\n\")\n",
    "print(f\"torch.sum(,0):\\n{torch.sum(aa, 0).numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vU7aAgfZBLXB",
    "outputId": "ff70ef60-ac5f-422a-dc51-a7e6df1fd9f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]]\n",
      "\n",
      " [[ 9 10 11]\n",
      "  [12 13 14]\n",
      "  [15 16 17]]\n",
      "\n",
      " [[18 19 20]\n",
      "  [21 22 23]\n",
      "  [24 25 26]]] \n",
      "\n",
      "manually compute sum() on the first dimension:\n",
      "[[[ 9. 12. 15.]]\n",
      "\n",
      " [[36. 39. 42.]]\n",
      "\n",
      " [[63. 66. 69.]]]\n",
      "\n",
      "torch.sum(,1):\n",
      "[[[ 9 12 15]]\n",
      "\n",
      " [[36 39 42]]\n",
      "\n",
      " [[63 66 69]]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  sum on the second dim, keeping dimensionality\n",
    "#\n",
    "\n",
    "aa = torch.tensor(range(27)).reshape(3,3,3)\n",
    "ss = torch.zeros(3,3).reshape(3,1,3)\n",
    "print(aa.numpy(),'\\n')\n",
    "for i in range(3):\n",
    "    for k in range(3):\n",
    "        ss[i,0,k] = torch.sum(aa[i,:, k])\n",
    "print(f\"manually compute sum() on the first dimension:\\n{ss.numpy()}\\n\")\n",
    "print(f\"torch.sum(,1):\\n{torch.sum(aa, 1, keepdim=True).numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "1NDDcLIDBRv0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "[[1. 0. 0.]\n",
      " [1. 1. 0.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "torch.sum(a, 1, keepdim=True).shape: torch.Size([3, 1])\n",
      "torch.sum(a, 1, keepdim=True:\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "This is sum over rows as expected\n",
      "\n",
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "print(f\"a=\\n{a.numpy()}\\n\")\n",
    "print(f\"torch.sum(a, 1, keepdim=True).shape: {torch.sum(a, 1, keepdim=True).shape}\")\n",
    "print(f\"torch.sum(a, 1, keepdim=True:\\n{torch.sum(a, 1, keepdim=True)}\")\n",
    "print(\"This is sum over rows as expected\\n\")\n",
    "\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: broadcasting at work!\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]]) \n",
      "\n",
      "SAME as if div = \n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3],\n",
      "        [4, 4, 4, 4]])\n",
      "\n",
      "wei/div =\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]])\n",
      "\n",
      "SAME result if div1 = tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "\n",
      "wei/div1 = tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]])\n",
      "\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]]) \n",
      "\n",
      "COMPARE: tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.5000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.5000, 0.3333, 0.0000],\n",
      "        [1.0000, 0.5000, 0.3333, 0.2500]])\n",
      "\n",
      "torch.sum(wei, dim=1, keepdim=True) =\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]])\n",
      "\n",
      "torch.sum(wei, dim=1, keepdim=True).shape = torch.Size([4, 1])\n",
      "\n",
      "torch.sum(wei, dim=1, keepdim=False) =\n",
      "tensor([1., 2., 3., 4.])\n",
      "\n",
      "torch.sum(wei, dim=1, keepdim=False).shape = torch.Size([4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "B,T,C = 4,4,4\n",
    "\n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei_keepdim = wei/torch.sum(wei, dim=1, keepdim=True)\n",
    "wei_no_keepdim = wei/torch.sum(wei, dim=1)\n",
    "\n",
    "print(\"IMPORTANT: broadcasting at work!\")\n",
    "print(wei_keepdim, '\\n')\n",
    "div = torch.tensor([[1,1,1,1], [2,2,2,2], [3,3,3,3], [4,4,4,4]])\n",
    "print(f\"SAME as if div = \\n{div}\\n\")\n",
    "print(f\"wei/div =\\n{wei/div}\\n\")\n",
    "div1=torch.tensor([[1,2,3,4]]).reshape(4,1)\n",
    "print(f\"SAME result if div1 = {div1}\\n\")\n",
    "print(f\"wei/div1 = {wei/div1}\\n\")\n",
    "print(wei/div, '\\n')\n",
    "print(f\"COMPARE: {wei_no_keepdim}\\n\")\n",
    "\n",
    "print(f\"torch.sum(wei, dim=1, keepdim=True) =\\n{torch.sum(wei, dim=1, keepdim=True)}\\n\")\n",
    "print(f\"torch.sum(wei, dim=1, keepdim=True).shape = {torch.sum(wei, dim=1, keepdim=True).shape}\\n\")\n",
    "\n",
    "print(f\"torch.sum(wei, dim=1, keepdim=False) =\\n{torch.sum(wei, dim=1, keepdim=False)}\\n\")\n",
    "print(f\"torch.sum(wei, dim=1, keepdim=False).shape = {torch.sum(wei, dim=1, keepdim=False).shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "div = torch.tensor([[1,1,1,1], [2,2,2,2], [3,3,3,3], [4,4,4,4]])\n",
    "print(wei/div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the actual matrix multiplication: a*b = \n",
      "[[ 7 10]\n",
      " [15 22]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a=np.matrix([[1, 2], [3, 4]])\n",
    "b=np.matrix([[1, 2], [3, 4]])\n",
    "\n",
    "print(f\"\\nThis is the actual matrix multiplication: a*b = \\n{a*b}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is element-wise multiplication a.b =\n",
      "[[ 1  4]\n",
      " [ 9 16]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[1, 2], [3, 4]])\n",
    "print(f\"This is element-wise multiplication a.b =\\n{(a*b).numpy()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pytorch matrix multiplication a@b =\n",
      "[[ 7 10]\n",
      " [15 22]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[1, 2], [3, 4]])\n",
    "print(f\"This is Pytorch matrix multiplication a@b =\\n{(a@b).numpy()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = torch.Size([4, 3, 3])\n",
      "wei.shape = torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "B,T,C = 4,3,3\n",
    "\n",
    "x = torch.randn(B,T,C)\n",
    "print(f\"x.shape = {x.shape}\")\n",
    "\n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei/torch.sum(wei, 1, keepdim=True)\n",
    "print(f\"wei.shape = {wei.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broadcasted on the first argument wei shape: torch.Size([4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "br = torch.tensor([])\n",
    "w = torch.unsqueeze(wei, dim=0)\n",
    "for b in range(B):\n",
    "    br = torch.cat((br,w),0)\n",
    "print(f\"broadcasted on the first argument wei shape: {br.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 3])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1=wei @ x\n",
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 3])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2=w @ x\n",
    "w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOATING ERROR .... \n",
      "w1 - w2 =\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 1.1921e-07, 1.3039e-08]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"FLOATING ERROR .... \\nw1 - w2 =\\n{w1 - w2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOATING ERROR .... \n",
      "w1 == w2:\n",
      "tensor([[[ True,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True, False, False]],\n",
      "\n",
      "        [[ True,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True,  True]],\n",
      "\n",
      "        [[ True,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True,  True]],\n",
      "\n",
      "        [[ True,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True,  True]]])\n",
      "\n",
      "But they are close: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"FLOATING ERROR .... \\nw1 == w2:\\n{w1 == w2}\\n\")\n",
    "print(f\"But they are close: {torch.allclose(w1,w2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Works just fine with integer-valued tensors:\n",
      "torch.equal(w @ x, wei @ x): True\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(100, (B,T,C))\n",
    "wei = torch.randint(100, (T,T))\n",
    "w = torch.unsqueeze(wei,0)\n",
    "print(f\"Works just fine with integer-valued tensors:\\ntorch.equal(w @ x, wei @ x): {torch.equal(w @ x, wei @ x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0.]])\n",
      "\n",
      "F.softmax(x, dim=0) = \n",
      "tensor([[0.3333, 0.1554, 0.2119, 0.3333],\n",
      "        [0.3333, 0.4223, 0.2119, 0.3333],\n",
      "        [0.3333, 0.4223, 0.5761, 0.3333]])\n",
      "\n",
      "Same assembled per column (dim=0):\n",
      "tensor([[0.3333, 0.1554, 0.2119, 0.3333],\n",
      "        [0.3333, 0.4223, 0.2119, 0.3333],\n",
      "        [0.3333, 0.4223, 0.5761, 0.3333]])\n"
     ]
    }
   ],
   "source": [
    "#x = torch.tensor(range(12)).reshape(3,4).to(torch.float64)\n",
    "x = torch.tril(torch.ones(3,4))\n",
    "print(f\"data:\\n{x}\\n\")\n",
    "\n",
    "print(f\"F.softmax(x, dim=0) = \\n{F.softmax(x, dim=0)}\\n\")\n",
    "\n",
    "res = []\n",
    "for j in range(x.shape[1]):\n",
    "    c = x[:,j]\n",
    "#     print(c)\n",
    "#     print(F.softmax(c, dim=0).T, '\\n')\n",
    "    res.append(F.softmax(c, dim=0))\n",
    "\n",
    "r = torch.stack(res, 1)\n",
    "print(f\"Same assembled per column (dim=0):\\n{r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0.]])\n",
      "\n",
      "F.softmax(x, dim=1) = \n",
      "tensor([[0.4754, 0.1749, 0.1749, 0.1749],\n",
      "        [0.3655, 0.3655, 0.1345, 0.1345],\n",
      "        [0.2969, 0.2969, 0.2969, 0.1092]])\n",
      "\n",
      "Same assembled per row (dim=1):\n",
      "tensor([[0.4754, 0.1749, 0.1749, 0.1749],\n",
      "        [0.3655, 0.3655, 0.1345, 0.1345],\n",
      "        [0.2969, 0.2969, 0.2969, 0.1092]])\n"
     ]
    }
   ],
   "source": [
    "#x = torch.tensor(range(12)).reshape(3,4).to(torch.float64)\n",
    "x = torch.tril(torch.ones(3,4))\n",
    "print(f\"data:\\n{x}\\n\")\n",
    "\n",
    "print(f\"F.softmax(x, dim=1) = \\n{F.softmax(x, dim=1)}\\n\")\n",
    "\n",
    "res = []\n",
    "for i in range(x.shape[0]):\n",
    "    c = x[i,:]\n",
    "#     print(c)\n",
    "#     print(F.softmax(c, dim=0).T, '\\n')\n",
    "    res.append(F.softmax(c, dim=0))\n",
    "\n",
    "r = torch.stack(res, 0)\n",
    "print(f\"Same assembled per row (dim=1):\\n{r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [6, 7, 8]]) \n",
      "\n",
      "tensor([[0, 2],\n",
      "        [3, 5],\n",
      "        [6, 8]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor(range(9)).reshape(3,3)\n",
    "print(t,'\\n')\n",
    "\n",
    "indices = torch.tensor([0,2])\n",
    "\n",
    "print(torch.index_select(t, 0, indices), '\\n')\n",
    "print(torch.index_select(t, 1, indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11],\n",
      "         [12, 13, 14],\n",
      "         [15, 16, 17]],\n",
      "\n",
      "        [[18, 19, 20],\n",
      "         [21, 22, 23],\n",
      "         [24, 25, 26]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2],\n",
       "         [ 6,  7,  8]],\n",
       "\n",
       "        [[ 9, 10, 11],\n",
       "         [15, 16, 17]],\n",
       "\n",
       "        [[18, 19, 20],\n",
       "         [24, 25, 26]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor(range(27)).reshape(3,3,3)\n",
    "print(t)\n",
    "\n",
    "indices = torch.tensor([0,2])\n",
    "\n",
    "torch.index_select(t, 1, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      "tensor([[ 1.,  0.,  0.],\n",
      "        [ 1.,  1.,  0.],\n",
      "        [ 1.,  1., 10.]])\n",
      "\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([ 0.,  0., 10.]) \n",
      "\n",
      "sum(..,0):\n",
      "tensor([ 3.,  2., 10.])\n",
      "\n",
      "----------------------\n",
      "\n",
      "sum(..,1):\n",
      "tensor([ 1.,  2., 12.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# sum: checking the obvious\n",
    "#\n",
    "\n",
    "a  = torch.tril(torch.ones(3,3))\n",
    "a[2,2] = 10\n",
    "print(f\"original:\\n{a}\\n\")\n",
    "\n",
    "\n",
    "print(a[:,0])\n",
    "print(a[:,1])\n",
    "print(a[:,2],'\\n')\n",
    "print(f\"sum(..,0):\\n{torch.sum(a, 0)}\\n\\n----------------------\\n\")\n",
    "\n",
    "print(f\"sum(..,1):\\n{torch.sum(a, 1)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      "tensor([[[ 1.,  0.,  0.],\n",
      "         [ 1.,  1.,  0.],\n",
      "         [ 1.,  1.,  1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 1.,  1.,  0.],\n",
      "         [ 1.,  1.,  1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 1.,  1.,  0.],\n",
      "         [ 1.,  1., 10.]]])\n",
      "\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([ 1.,  1., 10.])\n",
      "sum(..,0):\n",
      "tensor([[ 3.,  0.,  0.],\n",
      "        [ 3.,  3.,  0.],\n",
      "        [ 3.,  3., 12.]])\n",
      "\n",
      "----------------------\n",
      "\n",
      "sum(..,1):\n",
      "tensor([[ 3.,  2.,  1.],\n",
      "        [ 3.,  2.,  1.],\n",
      "        [ 3.,  2., 10.]])\n",
      "\n",
      "sum(..,2):\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 1.,  2.,  3.],\n",
      "        [ 1.,  2., 12.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# sum: checking the obvious\n",
    "#\n",
    "\n",
    "a  = torch.tril(torch.ones(3,3,3))\n",
    "a[2,2,2] = 10\n",
    "print(f\"original:\\n{a}\\n\")\n",
    "\n",
    "print(a[:,0,0])\n",
    "print(a[:,0,1])\n",
    "print(a[:,0,2])\n",
    "print(a[:,1,0])\n",
    "print(a[:,1,1])\n",
    "print(a[:,2,2])\n",
    "print(f\"sum(..,0):\\n{torch.sum(a, 0)}\\n\\n----------------------\\n\")\n",
    "\n",
    "print(f\"sum(..,1):\\n{torch.sum(a, 1)}\\n\")\n",
    "print(f\"sum(..,2):\\n{torch.sum(a, 2)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei =\n",
      "tensor([[0, 1, 1, 1, 1],\n",
      "        [1, 0, 1, 1, 1],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [1, 1, 1, 0, 1],\n",
      "        [1, 1, 1, 1, 0]], dtype=torch.int16)\n",
      "\n",
      "t =\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11],\n",
      "         [12, 13, 14],\n",
      "         [15, 16, 17]],\n",
      "\n",
      "        [[18, 19, 20],\n",
      "         [21, 22, 23],\n",
      "         [24, 25, 26]]])\n",
      "\n",
      "\n",
      "For example:\n",
      "\n",
      "t*wei =\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  0,  7,  8,  9],\n",
      "        [10, 11,  0, 13, 14],\n",
      "        [15, 16, 17,  0, 19],\n",
      "        [20, 21, 22, 23,  0]])\n"
     ]
    }
   ],
   "source": [
    "# Diagonal operation:\n",
    "T=5\n",
    "wei =torch.tril(torch.ones(T,T), diagonal=-1).to(torch.int16) + \\\n",
    "    torch.tril(torch.ones(T,T), diagonal=-1).mT.to(torch.int16)\n",
    "print(f\"wei =\\n{wei}\\n\")\n",
    "print(f\"t =\\n{t}\\n\")\n",
    "print('\\nFor example:\\n')\n",
    "\n",
    "t = torch.tensor(range(T**2)).reshape(T,T)\n",
    "\n",
    "print(f\"t*wei =\\n{t*wei}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0])\n",
      "torch.Size([2, 2])\n",
      "tensor([[5.6520e-02, 3.0730e-41],\n",
      "        [5.7994e-02, 3.0730e-41]])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# perhaps this is faster as it doesn't need to be initialized in comparison with\n",
    "# torch.zeros((2,2))\n",
    "#\n",
    "e = torch.empty((0,))\n",
    "print(e.shape)\n",
    "e1 = torch.empty((2,2))\n",
    "print(e1.shape)\n",
    "print(e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 8, 9, 2])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Apparently broadcasting to more than 1 dimension works just fine\n",
    "#    all that's required is that the data can be expanded without\n",
    "#    copying the data\n",
    "#\n",
    "\n",
    "a=torch.ones(    8,1,2)\n",
    "b=torch.ones(2,4,8,9,1)\n",
    "\n",
    "(a+b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]])\n",
      "\n",
      "VS\n",
      "\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]])\n",
      "\n",
      "wei == wei1: True\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Not sure what's the advantage of using masked_fill vs just [condition] operation:\n",
    "#\n",
    "T=5\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros(T,T)\n",
    "wei[tril == 0] = float('-inf')\n",
    "wei = torch.softmax(wei, dim=1)\n",
    "print(wei)\n",
    "\n",
    "print('\\nVS\\n')\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei1 = torch.zeros(T,T)\n",
    "wei1 = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei1 = torch.softmax(wei1, dim=1)\n",
    "print(wei1)\n",
    "\n",
    "print(f\"\\nwei == wei1: {torch.allclose(wei1, wei)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "t=\n",
      "tensor([[0., 1.],\n",
      "        [2., 3.]])\n",
      "\n",
      "\n",
      "==================================\n",
      "\n",
      "For unsqueeze ss1.shape=torch.Size([2, 1])\n",
      "\n",
      "s1=\n",
      "tensor([[1.],\n",
      "        [5.]])\n",
      "\n",
      "\n",
      "==================================\n",
      "\n",
      "For keepdim=False, s1.shape=torch.Size([2])\n",
      "\n",
      "s1 =\n",
      "tensor([1., 5.])\n",
      "\n",
      "t/s1 =\n",
      "tensor([[0.0000, 0.2000],\n",
      "        [2.0000, 0.6000]])\n",
      "\n",
      "\n",
      "==================================\n",
      "\n",
      "For keepdim=True, s1.shape=torch.Size([2, 1])\n",
      "\n",
      "s1=\n",
      "tensor([[1.],\n",
      "        [5.]])\n",
      "\n",
      "t/s1 =\n",
      "tensor([[0.0000, 1.0000],\n",
      "        [0.4000, 0.6000]])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  torch.sum() again (!!!)\n",
    "#  ROW normalizaton in particular\n",
    "#\n",
    "\n",
    "t = torch.Tensor(range(4)).reshape(2,2)\n",
    "print(f'\\nt=\\n{t}\\n')\n",
    "print('\\n==================================\\n')\n",
    "\n",
    "# add an empty column dim converting the result from a 1-d row to a 2-d column:\n",
    "s1=torch.unsqueeze(torch.sum(t,dim=1), dim=1)\n",
    "print(f\"For unsqueeze s{s1.shape=}\\n\")\n",
    "print(f\"s1=\\n{s1}\\n\")\n",
    "print('\\n==================================\\n')\n",
    "\n",
    "s1=torch.sum(t,dim=1)\n",
    "print(f\"For keepdim=False, {s1.shape=}\\n\")\n",
    "print(f\"s1 =\\n{s1}\\n\")\n",
    "print(f\"t/s1 =\\n{t/s1}\\n\")\n",
    "\n",
    "#\n",
    "#  produces the same result as\n",
    "#\n",
    "print('\\n==================================\\n')\n",
    "s1 = torch.sum(t, dim=1, keepdim=True)\n",
    "print(f\"For keepdim=True, {s1.shape=}\\n\")\n",
    "print(f\"s1=\\n{s1}\\n\")\n",
    "print(f\"t/s1 =\\n{t/s1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=\n",
      "tensor([[0., 1.],\n",
      "        [2., 3.]])\n",
      "\n",
      "s1=\n",
      "tensor([1., 5.])\n",
      "\n",
      "shapes:\n",
      "   torch.Size([2])\n",
      "torch.Size([2, 2])\n",
      "\n",
      "t/s1=\n",
      "tensor([[0.0000, 0.2000],\n",
      "        [2.0000, 0.6000]])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# this is about broadcasting\n",
    "#\n",
    "print(f\"t=\\n{t}\\n\")\n",
    "s1 = torch.sum(t, dim=1, keepdim=False) # keepdim is False by default\n",
    "print(f\"s1=\\n{s1}\\n\")\n",
    "print('shapes:\\n  ', s1.shape)\n",
    "print(t.shape)\n",
    "#\n",
    "# so tensors align as \n",
    "#     [2,1] and\n",
    "#     [2,2]\n",
    "# \n",
    "#  so after broadcasting \n",
    "#\n",
    "#  if s1 = [[x],\n",
    "#           [y]]\n",
    "#\n",
    "#  it actually can be thought of as:\n",
    "#\n",
    "#  s1 = [[x,x]\n",
    "#        [x,y]]\n",
    "#\n",
    "#  and element-wise division results in \n",
    "#      the row column divided by x and second by y:\n",
    "#\n",
    "print(f\"\\nt/s1=\\n{t/s1}\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Generator().manual_seed(2147483647): tensor([-0.9800, -1.6578, -0.0572])\n",
      "torch.manual_seed(2147483647):             tensor([-0.9800, -1.6578, -0.0572])\n",
      "\n",
      "torch.randn(3, generator=g1): tensor([-0.9800, -1.6578, -0.0572])\n",
      "torch.randn(3, generator=g2): tensor([-0.9800, -1.6578, -0.0572])\n"
     ]
    }
   ],
   "source": [
    "# RN generator\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "print(f\"torch.Generator().manual_seed(2147483647): {torch.randn(3, generator=g)}\")\n",
    "\n",
    "# same as\n",
    "torch.manual_seed(2147483647)\n",
    "print(f\"torch.manual_seed(2147483647):             {torch.randn(3)}\")\n",
    "\n",
    "# but generator allows for parallel RN generation:\n",
    "g1 = torch.Generator().manual_seed(2147483647)\n",
    "g2 = torch.Generator().manual_seed(2147483647)\n",
    "print(f\"\\ntorch.randn(3, generator=g1): {torch.randn(3, generator=g1)}\")\n",
    "print(f\"torch.randn(3, generator=g2): {torch.randn(3, generator=g2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.],\n",
      "        [2., 3.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# used in model smoothing:\n",
    "#\n",
    "\n",
    "N = torch.Tensor(range(4)).reshape(2,2)\n",
    "print(N)\n",
    "print(N+1) #elementwise addition to avoid log(p) becoming -inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[[range(3)], [0,2,1]] = tensor([[1, 6, 8]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 2],\n",
       "        [4, 6, 5],\n",
       "        [7, 9, 8]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "x_ind = [range(3)]\n",
    "y_ind = [0,2,1]\n",
    "print(f\"x[[range(3)], [0,2,1]] = {x[x_ind, y_ind]}\")\n",
    "x[:, [0,2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2, 3],\n",
      "         [4, 5],\n",
      "         [6, 7],\n",
      "         [2, 3],\n",
      "         [4, 5],\n",
      "         [6, 7],\n",
      "         [2, 3],\n",
      "         [4, 5],\n",
      "         [6, 7],\n",
      "         [2, 3],\n",
      "         [4, 5],\n",
      "         [6, 7]]])\n",
      "\n",
      "x-ind and y-ind need to be the same length:\n",
      "D[range(1,3),range(0,2)] = tensor([2, 5]) <--- \n",
      "\n",
      "This doesn't work: D[range(1,4),range(0,2)]\n",
      "\n",
      "But this does:\n",
      "D[1:5, :] = \n",
      "tensor([[2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7],\n",
      "        [8, 9]])\n",
      "\n",
      "D[1:5,range(0,2)] = \n",
      "tensor([[2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7],\n",
      "        [8, 9]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "D = torch.tensor(range(16)).reshape(8,2)\n",
    "\n",
    "print(f\"{D[torch.tensor([4*[1,2,3]])]}\\n\")\n",
    "print(\"x-ind and y-ind need to be the same length:\")\n",
    "print(f\"D[range(1,3),range(0,2)] = {D[range(1,3),range(0,2)]} <--- \\n\")\n",
    "print(\"This doesn't work: D[range(1,4),range(0,2)]\")\n",
    "#print(f\"{D[range(1,4),range(0,2)]}\")\n",
    "print(\"\\nBut this does:\")\n",
    "print(f\"D[1:5, :] = \\n{D[1:5,:]}\\n\")\n",
    "print(f\"D[1:5,range(0,2)] = \\n{D[1:5,range(0,2)]}\\n\")\n",
    "#torch.tensor([range(1,6), range(0,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D.shape = torch.Size([8, 2])\n",
      "torch.tensor(([[0,1],[1,0]])).shape = torch.Size([2, 2])\n",
      "\n",
      "========================================\n",
      "\n",
      "D[[[0,1],[1,0]]].shape = torch.Size([2])\n",
      "D[torch.tensor(([[0,1],[1,0]]))].shape = torch.Size([2, 2, 2])\n",
      "D[torch.tensor([3*[0,1]])].shape = torch.Size([1, 6, 2])\n",
      "D[torch.tensor([3*[[0,1]]])].shape = torch.Size([1, 3, 2, 2])\n",
      "D[torch.tensor([3*[0,1]])].shape = torch.Size([1, 6, 2])\n",
      "\n",
      "========================================\n",
      "\n",
      "D[torch.tensor(([[0,1],[1,0]]))] =\n",
      "tensor([[[0, 1],\n",
      "         [2, 3]],\n",
      "\n",
      "        [[2, 3],\n",
      "         [0, 1]]])\n",
      "\n",
      "D[torch.tensor([3*[0,1]])] =\n",
      "tensor([[[0, 1],\n",
      "         [2, 3],\n",
      "         [0, 1],\n",
      "         [2, 3],\n",
      "         [0, 1],\n",
      "         [2, 3]]])\n",
      "\n",
      "\n",
      "=====================\n",
      "\n",
      "D[torch.tensor([3*[[0,1]]])] =\n",
      "tensor([[[[0, 1],\n",
      "          [2, 3]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [2, 3]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [2, 3]]]])\n",
      "\n",
      "[3*[[0,1]]] = [[[0, 1], [0, 1], [0, 1]]]\n",
      "\n",
      "=====================\n",
      "\n",
      "D[torch.tensor([3*[0,1]])] =\n",
      "tensor([[[0, 1],\n",
      "         [2, 3],\n",
      "         [0, 1],\n",
      "         [2, 3],\n",
      "         [0, 1],\n",
      "         [2, 3]]])\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "torch.tensor(([[0,1],[1,0]])) =\n",
      "tensor([[0, 1],\n",
      "        [1, 0]])\n",
      "\n",
      "D[torch.tensor(([[0,1],[1,0]]))] =\n",
      "tensor([[[0, 1],\n",
      "         [2, 3]],\n",
      "\n",
      "        [[2, 3],\n",
      "         [0, 1]]])\n",
      "\n",
      "torch.tensor(([[0,1])) =\n",
      "tensor([0, 1])\n",
      "\n",
      "D[torch.tensor(([[0,1]))] =\n",
      "tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "\n",
      "\n",
      "========================================\n",
      "\n",
      "D[[[0,1],[1,0]]] =\n",
      "tensor([1, 2])\n",
      "\n",
      "D[[[0,1]]] =\n",
      "tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "\n",
      "D[[0,1]] =\n",
      "tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "\n",
      "D[0,1] = 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"{D.shape = }\")\n",
    "print(f\"torch.tensor(([[0,1],[1,0]])).shape = {torch.tensor(([[0,1],[1,0]])).shape}\")\n",
    "print(\"\\n========================================\\n\")\n",
    "\n",
    "print(f\"D[[[0,1],[1,0]]].shape = {D[[[0,1],[1,0]]].shape}\")\n",
    "print(f\"D[torch.tensor(([[0,1],[1,0]]))].shape = {D[torch.tensor(([0,1],[1,0]))].shape}\")\n",
    "print(f\"D[torch.tensor([3*[0,1]])].shape = {D[torch.tensor([3*[0,1]])].shape}\")\n",
    "print(f\"D[torch.tensor([3*[[0,1]]])].shape = {D[torch.tensor([3*[[0,1]]])].shape}\")\n",
    "print(f\"D[torch.tensor([3*[0,1]])].shape = {D[torch.tensor([3*[0,1]])].shape}\")\n",
    "print(\"\\n========================================\\n\")\n",
    "\n",
    "print(f\"D[torch.tensor(([[0,1],[1,0]]))] =\\n{D[torch.tensor(([0,1],[1,0]))]}\\n\")\n",
    "print(f\"D[torch.tensor([3*[0,1]])] =\\n{D[torch.tensor([3*[0,1]])]}\\n\")\n",
    "\n",
    "print(\"\\n=====================\\n\")\n",
    "print(f\"D[torch.tensor([3*[[0,1]]])] =\\n{D[torch.tensor([3*[[0,1]]])]}\\n\")\n",
    "print(f\"{[3*[[0,1]]] = }\")\n",
    "print(\"\\n=====================\\n\")\n",
    "\n",
    "print(f\"D[torch.tensor([3*[0,1]])] =\\n{D[torch.tensor([3*[0,1]])]}\\n\")\n",
    "print(\"\\n========================================\\n\")\n",
    "\n",
    "print(f\"torch.tensor(([[0,1],[1,0]])) =\\n{torch.tensor(([0,1],[1,0]))}\\n\")\n",
    "print(f\"D[torch.tensor(([[0,1],[1,0]]))] =\\n{D[torch.tensor(([0,1],[1,0]))]}\\n\")\n",
    "print(f\"torch.tensor(([[0,1])) =\\n{torch.tensor(([0,1]))}\\n\")\n",
    "#print(f\"torch.tensor(([[0,1])).shape =\\n{torch.tensor(([0,1])).shape}\\n\")\n",
    "print(f\"D[torch.tensor(([[0,1]))] =\\n{D[torch.tensor(([0,1]))]}\\n\")\n",
    "print(\"\\n========================================\\n\")\n",
    "\n",
    "\n",
    "print(f\"D[[[0,1],[1,0]]] =\\n{D[[[0,1],[1,0]]]}\\n\")\n",
    "print(f\"D[[[0,1]]] =\\n{D[[[0,1]]]}\\n\")\n",
    "print(f\"D[[0,1]] =\\n{D[[0,1]]}\\n\")\n",
    "print(f\"D[0,1] = {D[0,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11],\n",
      "         [12, 13, 14],\n",
      "         [15, 16, 17]],\n",
      "\n",
      "        [[18, 19, 20],\n",
      "         [21, 22, 23],\n",
      "         [24, 25, 26]]]) \n",
      "\n",
      "tensor(13)\n",
      "tensor([[ 9, 10, 11],\n",
      "        [12, 13, 14],\n",
      "        [15, 16, 17]])\n",
      "tensor([12, 13, 14])\n",
      "tensor([12, 13, 14]) \n",
      "\n",
      "tensor([12, 13, 14])\n",
      "tensor([ 4, 13, 22])\n"
     ]
    }
   ],
   "source": [
    "DDD = torch.tensor(range(27)).reshape(3,3,3)\n",
    "print(DDD, '\\n')\n",
    "print(DDD[1,1,1])\n",
    "print(DDD[1])\n",
    "print(DDD[1,1,])\n",
    "print(DDD[1,1],'\\n')\n",
    "print(DDD[1,1,:])\n",
    "print(DDD[:,1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14, 15]])\n",
      "D1[:,ind] = tensor([[ 0,  1,  2],\n",
      "        [ 8,  9, 10]])\n",
      "D[ind] = tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n",
      "D[range(3)] = tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "D1 = D.view(2,-1)\n",
    "print(D1)\n",
    "ind = torch.tensor(range(3))\n",
    "print(f\"{D1[:,ind] = }\")\n",
    "print(f\"{D[ind] = }\")\n",
    "print(f\"{D[range(3)] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X.shape = torch.Size([100, 3])\n",
      "C.shape = torch.Size([27, 2])\n",
      "X[0].shape = torch.Size([3])\n",
      "\n",
      "\n",
      "X[0] = tensor([0, 1, 2])\n",
      "\n",
      "C[C[:,0]<0,0] = \n",
      "{C[C[:,0]<0,0]}\n",
      "\n",
      "C[X[0]] =\n",
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n",
      "C[[[1,2,3,4], [1]]] =\n",
      "tensor([3, 5, 7, 9])\n",
      "\n",
      "C[[[1,2,3,4]]] =\n",
      "tensor([[2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7],\n",
      "        [8, 9]])\n",
      "\n",
      "C[[range(1,5)], [range(1,2)]] = \n",
      "tensor([[3, 5, 7, 9]])\n",
      "\n",
      "C[1:5, range(1,2)] = \n",
      "tensor([[3],\n",
      "        [5],\n",
      "        [7],\n",
      "        [9]])\n",
      "\n",
      "C[1:5, [range(1,2)]] = \n",
      "tensor([[[3]],\n",
      "\n",
      "        [[5]],\n",
      "\n",
      "        [[7]],\n",
      "\n",
      "        [[9]]])\n",
      "\n",
      "C[1:5, 1:2] = \n",
      "tensor([[3],\n",
      "        [5],\n",
      "        [7],\n",
      "        [9]])\n",
      "\n",
      "C[torch.tensor([[1,2,3],[4,5,6]])] = tensor([[[ 2,  3],\n",
      "         [ 4,  5],\n",
      "         [ 6,  7]],\n",
      "\n",
      "        [[ 8,  9],\n",
      "         [10, 11],\n",
      "         [12, 13]]])\n",
      "C[X[1,2]] = tensor([10, 11])\n"
     ]
    }
   ],
   "source": [
    "C=torch.tensor(range(54)).reshape(27,2)\n",
    "X=torch.tensor(range(300)).reshape(100,3)\n",
    "\n",
    "print(f\"\\n{X.shape = }\")\n",
    "print(f\"{C.shape = }\")\n",
    "\n",
    "print(f\"{X[0].shape = }\\n\\n\")\n",
    "print(f\"{X[0] = }\\n\")\n",
    "print(\"C[C[:,0]<0,0] = \\n{C[C[:,0]<0,0]}\\n\")\n",
    "print(f\"C[X[0]] =\\n{C[X[0]]}\")\n",
    "print(f\"C[[[1,2,3,4], [1]]] =\\n{C[[[1,2,3,4], [1]]]}\\n\")\n",
    "print(f\"C[[[1,2,3,4]]] =\\n{C[[[1,2,3,4]]]}\\n\")\n",
    "print(f\"C[[range(1,5)], [range(1,2)]] = \\n{C[[range(1,5)], [range(1,2)]]}\\n\")\n",
    "print(f\"C[1:5, range(1,2)] = \\n{C[1:5,range(1,2)]}\\n\")\n",
    "print(f\"C[1:5, [range(1,2)]] = \\n{C[1:5, [range(1,2)]]}\\n\")\n",
    "print(f\"C[1:5, 1:2] = \\n{C[1:5, 1:2]}\\n\")\n",
    "\n",
    "print(f\"{C[torch.tensor([[1,2,3],[4,5,6]])] = }\")\n",
    "print(f\"{C[X[1,2]] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[[1,2,3],:] = tensor([[ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "\n",
      "X[[1,2,3]] = tensor([[ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "\n",
      "X[torch.tensor([1,2,3]),:] = tensor([[ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "X[[1,2,3],0:2] = tensor([[ 3,  4],\n",
      "        [ 6,  7],\n",
      "        [ 9, 10]])\n",
      "\n",
      "X[torch.tensor([1,2,3]),0:2] = tensor([[ 3,  4],\n",
      "        [ 6,  7],\n",
      "        [ 9, 10]])\n",
      "\n",
      "torch.tensor(range(2)).shape = torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X[[1,2,3],:] = }\\n\")\n",
    "print(f\"{X[[1,2,3]] = }\\n\")\n",
    "print(f\"{X[torch.tensor([1,2,3]),:] = }\")\n",
    "\n",
    "\n",
    "print(\"\\n====================================\\n\")\n",
    "print(f\"\\n{X[[1,2,3],0:2] = }\\n\")\n",
    "print(f\"{X[torch.tensor([1,2,3]),0:2] = }\\n\")\n",
    "\n",
    "# not clear, this wants broadcasting:\n",
    "# --> IndexError: shape mismatch: indexing tensors could not be broadcast together with shapes [3], [2]\n",
    "#print(f\"{X[torch.tensor([1,2,3]),torch.tensor(range(2))] = }\")\n",
    "\n",
    "print(f\"{torch.tensor(range(2)).shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "O = tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "O_str = tensor([1., 1., 1.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(range(9)).reshape(3,3).float()\n",
    "O = torch.ones(3,3)\n",
    "O_str = torch.ones(3)\n",
    "print(f\"{X = }\")\n",
    "print(f\"{O = }\")\n",
    "print(f\"{O_str = }\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X+O = tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "X+O_str = tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "torch.equal(X + O, X + O_str) = True\n",
      "X + torch.ones(3,3) = tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "torch.equal(X+O, X + torch.ones(3,3)) = True\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X+O = }\")\n",
    "print(f\"{X+O_str = }\")\n",
    "print(f\"{torch.equal(X + O, X + O_str) = }\")\n",
    "print(f\"{X + torch.ones(3,3) = }\")\n",
    "print(f\"{torch.equal(X+O, X + torch.ones(3,3)) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = tensor([[0., 1., 2., 1.],\n",
      "        [3., 4., 5., 1.],\n",
      "        [6., 7., 8., 1.]])\n",
      "O1 = tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# this works but looks bad:\n",
    "#\n",
    "X1 = torch.stack(*[[*torch.unbind(X, dim=1)] + [torch.ones(3)]], dim=1)\n",
    "O1 = torch.stack(*[[*torch.unbind(torch.eye(3), dim=1)] + [torch.ones(3)]], dim=0)\n",
    "print(f\"{X1 = }\")\n",
    "print(f\"{O1 = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[5., 1., 0., 0.],\n",
      "        [5., 0., 1., 0.],\n",
      "        [5., 0., 0., 1.]])\n",
      "tensor([[1., 0., 0., 5.],\n",
      "        [0., 1., 0., 5.],\n",
      "        [0., 0., 1., 5.]])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# a variant with constant padding:\n",
    "#\n",
    "E = torch.eye(3)\n",
    "print(E)\n",
    "f10 = torch.nn.ConstantPad1d((1,0), 5)\n",
    "f01 = torch.nn.ConstantPad1d((0,1), 5)\n",
    "print(f10(E))\n",
    "print(f01(E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = tensor([[0., 1., 2., 1.],\n",
      "        [3., 4., 5., 1.],\n",
      "        [6., 7., 8., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# this looks much better, just add a fake dimension to ones making them 1x3 on creation\n",
    "#\n",
    "X1 = torch.cat([X, torch.ones(3,1)], dim=1)\n",
    "print(f\"{X1 = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OU.shape = torch.Size([1, 3])\n",
      "X1 = tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.],\n",
      "        [1., 1., 1.]])\n",
      "OU.shape = torch.Size([3, 1])\n",
      "X1 = tensor([[0., 1., 2., 1.],\n",
      "        [3., 4., 5., 1.],\n",
      "        [6., 7., 8., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# this also looks much better, just add a fake dimension to ones making them 1x3 using unsqueeze\n",
    "#\n",
    "OU = torch.unsqueeze(torch.ones(3), 0)\n",
    "print(f\"{OU.shape = }\")\n",
    "X1 = torch.cat([X, OU], dim=0)\n",
    "print(f\"{X1 = }\")\n",
    "\n",
    "OU = torch.unsqueeze(torch.ones(3), 1)\n",
    "print(f\"{OU.shape = }\")\n",
    "X1 = torch.cat([X, OU], dim=1)\n",
    "print(f\"{X1 = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[0. 1. 2.]\n",
      " [3. 4. 5.]\n",
      " [6. 7. 8.]]\n",
      "\n",
      "O:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "X1:\n",
      "[[0. 1. 2. 1.]\n",
      " [3. 4. 5. 1.]\n",
      " [6. 7. 8. 1.]]\n",
      "\n",
      "O1:\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "X1 @ O1:\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "\n",
      "X+O:\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(f\"X:\\n{X.numpy()}\\n\")\n",
    "print(f\"O:\\n{O.numpy()}\\n\")\n",
    "print(f\"X1:\\n{X1.numpy()}\\n\")\n",
    "print(f\"O1:\\n{O1.numpy()}\\n\")\n",
    "print(f\"X1 @ O1:\\n{(X1 @ O1).numpy()}\\n\")\n",
    "print(f\"X+O:\\n{(X+O).numpy()}\\n\")\n",
    "print(torch.equal(X1 @ O1, X + O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1:\n",
      "[[0. 1. 2. 1.]\n",
      " [3. 4. 5. 1.]\n",
      " [6. 7. 8. 1.]]\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 2. 3.]] \n",
      "\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 2. 3.]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [1., 2., 3.],\n",
       "        [1., 2., 3.]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = torch.tensor(range(1,4)).float()\n",
    "X1 = torch.cat((X, torch.unsqueeze(torch.ones(3), dim=1)), dim=1)\n",
    "print('X1:\\n', X1.numpy(), '\\n', sep='')\n",
    "\n",
    "M = torch.cat((torch.eye(3), torch.unsqueeze(R, dim=0)), dim=0)\n",
    "print(M.numpy(), '\\n')\n",
    "\n",
    "X1 @ M\n",
    "\n",
    "M1 = torch.cat((torch.zeros(3,3), torch.unsqueeze(R, dim=0)), dim=0)\n",
    "print(M1.numpy(), '\\n')\n",
    "\n",
    "X1 @ M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(R, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.],\n",
      "        [1., 2., 3.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# duplicate a row:\n",
    "#\n",
    "\n",
    "print(torch.zeros(3,3)+R)\n",
    "\n",
    "#\n",
    "# duplicate a column:\n",
    "#\n",
    "\n",
    "print(torch.zeros(3,3) + torch.unsqueeze(R, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1 = torch.arange(16).reshape(4,4)\n",
    "#\n",
    "#  so much for this: :)\n",
    "#\n",
    "T2 = torch.tensor(range(16)).reshape(4,4)\n",
    "torch.equal(T1,T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "tensor([ 0,  5, 10, 15])\n"
     ]
    }
   ],
   "source": [
    "print(T1)\n",
    "print(T1[range(4),range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11],\n",
      "         [12, 13, 14],\n",
      "         [15, 16, 17]],\n",
      "\n",
      "        [[18, 19, 20],\n",
      "         [21, 22, 23],\n",
      "         [24, 25, 26]]])\n",
      "tensor([ 0, 13, 26])\n"
     ]
    }
   ],
   "source": [
    "T3=torch.arange(27).reshape(3,3,3)\n",
    "print(T3)\n",
    "print(T3[range(3), range(3), range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n",
      "\n",
      "T2[:, torch.tensor([1,2])][torch.tensor([1,2]),:] =\n",
      "[[ 5  6]\n",
      " [ 9 10]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "T2 = torch.tensor(range(16)).reshape(4,4)\n",
    "print(f\"{T2.numpy()}\\n\")\n",
    "Center = T2[:, torch.tensor([1,2])][torch.tensor([1,2]),:]\n",
    "print(f\"T2[:, torch.tensor([1,2])][torch.tensor([1,2]),:] =\\n{Center.numpy()}\\n\", sep='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3],\n",
       "        [0, 1, 2, 3],\n",
       "        [0, 1, 2, 3],\n",
       "        [0, 1, 2, 3]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Because of broadcasting, addition isn't commutative in pytorch :) \n",
    "#\n",
    "T2 + torch.arange(4) - T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.equal(T2F/np.exp(1)*np.exp(1), T2F) = False\n",
      "torch.allclose(T2F/np.exp(1)*np.exp(1), T2F) = True\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  division isn't commutative either:\n",
    "#\n",
    "T2F = T2.float()\n",
    "print(f\"{torch.equal(T2F/np.exp(1)*np.exp(1), T2F) = }\")\n",
    "print(f\"{torch.allclose(T2F/np.exp(1)*np.exp(1), T2F) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(2.1417)\n",
      "tensor(2.6222)\n",
      "tensor(2.7049)\n",
      "tensor(2.7165)\n",
      "tensor(2.7180)\n",
      "tensor(2.7182)\n",
      "tensor(2.7183)\n",
      "tensor(2.7183)\n",
      "tensor(2.7183)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   logits seem to be interpreted so that exp(logit) ~ \"count\", which is \n",
    "#          strange as exp(logit) quickly approaches \"e\"\n",
    "#\n",
    "for i in range(10):\n",
    "    logit = tanh(torch.tensor(i))\n",
    "    print(exp(logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.7183, 2.7183, 2.7183, 2.7183, 2.7183, 2.7183, 2.7183, 2.7183, 2.7183,\n",
      "        2.7183])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "loss = tensor(23.0259)\n"
     ]
    }
   ],
   "source": [
    "logits = torch.ones(10).float()\n",
    "counts = logits.exp()\n",
    "\n",
    "print(counts)\n",
    "print(logits)\n",
    "loss = F.cross_entropy(logits, logits)\n",
    "print(f\"{loss = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits =\n",
      "[[ 1. -1. -1. -1. -1.]\n",
      " [ 1. -1. -1. -1. -1.]\n",
      " [ 1. -1. -1. -1. -1.]]\n",
      "\n",
      "prob = \n",
      "[[0.65 0.09 0.09 0.09 0.09]\n",
      " [0.65 0.09 0.09 0.09 0.09]\n",
      " [0.65 0.09 0.09 0.09 0.09]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.43265\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[ 1. -2. -2. -2. -2.]\n",
      " [ 1. -2. -2. -2. -2.]\n",
      " [ 1. -2. -2. -2. -2.]]\n",
      "\n",
      "prob = \n",
      "[[0.83 0.04 0.04 0.04 0.04]\n",
      " [0.83 0.04 0.04 0.04 0.04]\n",
      " [0.83 0.04 0.04 0.04 0.04]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.18161\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[ 1. -3. -3. -3. -3.]\n",
      " [ 1. -3. -3. -3. -3.]\n",
      " [ 1. -3. -3. -3. -3.]]\n",
      "\n",
      "prob = \n",
      "[[0.93 0.02 0.02 0.02 0.02]\n",
      " [0.93 0.02 0.02 0.02 0.02]\n",
      " [0.93 0.02 0.02 0.02 0.02]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.07070\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[ 1. -4. -4. -4. -4.]\n",
      " [ 1. -4. -4. -4. -4.]\n",
      " [ 1. -4. -4. -4. -4.]]\n",
      "\n",
      "prob = \n",
      "[[0.97 0.01 0.01 0.01 0.01]\n",
      " [0.97 0.01 0.01 0.01 0.01]\n",
      " [0.97 0.01 0.01 0.01 0.01]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.02659\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[ 1. -5. -5. -5. -5.]\n",
      " [ 1. -5. -5. -5. -5.]\n",
      " [ 1. -5. -5. -5. -5.]]\n",
      "\n",
      "prob = \n",
      "[[0.99 0.   0.   0.   0.  ]\n",
      " [0.99 0.   0.   0.   0.  ]\n",
      " [0.99 0.   0.   0.   0.  ]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.00987\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[ 1. -6. -6. -6. -6.]\n",
      " [ 1. -6. -6. -6. -6.]\n",
      " [ 1. -6. -6. -6. -6.]]\n",
      "\n",
      "prob = \n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.00364\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[ 1. -7. -7. -7. -7.]\n",
      " [ 1. -7. -7. -7. -7.]\n",
      " [ 1. -7. -7. -7. -7.]]\n",
      "\n",
      "prob = \n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.00134\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[ 1. -8. -8. -8. -8.]\n",
      " [ 1. -8. -8. -8. -8.]\n",
      " [ 1. -8. -8. -8. -8.]]\n",
      "\n",
      "prob = \n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.00049\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[ 1. -9. -9. -9. -9.]\n",
      " [ 1. -9. -9. -9. -9.]\n",
      " [ 1. -9. -9. -9. -9.]]\n",
      "\n",
      "prob = \n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.00018\n",
      "\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_samp = 3\n",
    "\n",
    "for mult in range(1,10):\n",
    "    \n",
    "    # 0-th column is 1, while the rest become more and more negative\n",
    "    logits = -mult*torch.ones(n_samp,5)\n",
    "    logits[:,0] = 1\n",
    "    \n",
    "    print(f\"logits =\\n{logits.numpy()}\\n\", sep='')\n",
    "    prob = F.softmax(logits, dim=1)\n",
    "    prob = torch.round(F.softmax(logits, dim=1), decimals = 2)\n",
    "    print(f\"prob = \\n{prob.numpy()}\\n\", sep='')\n",
    "    g_truth = torch.zeros(n_samp).to(torch.int64)\n",
    "    print(f\"ground truth: {g_truth.numpy()}\")\n",
    "    loss = F.cross_entropy(logits, g_truth)\n",
    "    print(f\"loss = {loss.numpy():.5f}\\n\\n======================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits =\n",
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n",
      "\n",
      "prob = \n",
      "[[0.2 0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2 0.2]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 1.60944\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[2. 1. 1. 1. 1.]\n",
      " [2. 1. 1. 1. 1.]\n",
      " [2. 1. 1. 1. 1.]]\n",
      "\n",
      "prob = \n",
      "[[0.4  0.15 0.15 0.15 0.15]\n",
      " [0.4  0.15 0.15 0.15 0.15]\n",
      " [0.4  0.15 0.15 0.15 0.15]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.90483\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[3. 1. 1. 1. 1.]\n",
      " [3. 1. 1. 1. 1.]\n",
      " [3. 1. 1. 1. 1.]]\n",
      "\n",
      "prob = \n",
      "[[0.65 0.09 0.09 0.09 0.09]\n",
      " [0.65 0.09 0.09 0.09 0.09]\n",
      " [0.65 0.09 0.09 0.09 0.09]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.43265\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[4. 1. 1. 1. 1.]\n",
      " [4. 1. 1. 1. 1.]\n",
      " [4. 1. 1. 1. 1.]]\n",
      "\n",
      "prob = \n",
      "[[0.83 0.04 0.04 0.04 0.04]\n",
      " [0.83 0.04 0.04 0.04 0.04]\n",
      " [0.83 0.04 0.04 0.04 0.04]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.18161\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[5. 1. 1. 1. 1.]\n",
      " [5. 1. 1. 1. 1.]\n",
      " [5. 1. 1. 1. 1.]]\n",
      "\n",
      "prob = \n",
      "[[0.93 0.02 0.02 0.02 0.02]\n",
      " [0.93 0.02 0.02 0.02 0.02]\n",
      " [0.93 0.02 0.02 0.02 0.02]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.07070\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[6. 1. 1. 1. 1.]\n",
      " [6. 1. 1. 1. 1.]\n",
      " [6. 1. 1. 1. 1.]]\n",
      "\n",
      "prob = \n",
      "[[0.97 0.01 0.01 0.01 0.01]\n",
      " [0.97 0.01 0.01 0.01 0.01]\n",
      " [0.97 0.01 0.01 0.01 0.01]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.02659\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[7. 1. 1. 1. 1.]\n",
      " [7. 1. 1. 1. 1.]\n",
      " [7. 1. 1. 1. 1.]]\n",
      "\n",
      "prob = \n",
      "[[0.99 0.   0.   0.   0.  ]\n",
      " [0.99 0.   0.   0.   0.  ]\n",
      " [0.99 0.   0.   0.   0.  ]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.00987\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[8. 1. 1. 1. 1.]\n",
      " [8. 1. 1. 1. 1.]\n",
      " [8. 1. 1. 1. 1.]]\n",
      "\n",
      "prob = \n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.00364\n",
      "\n",
      "======================\n",
      "\n",
      "logits =\n",
      "[[9. 1. 1. 1. 1.]\n",
      " [9. 1. 1. 1. 1.]\n",
      " [9. 1. 1. 1. 1.]]\n",
      "\n",
      "prob = \n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "\n",
      "ground truth: [0 0 0]\n",
      "loss = 0.00134\n",
      "\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_samp = 3\n",
    "\n",
    "for pluser in range(1,10):\n",
    "    \n",
    "    # ones except for col #0 which gradually increases\n",
    "    logits = torch.ones(n_samp,5)\n",
    "    logits[:,0] = pluser\n",
    "    \n",
    "    print(f\"logits =\\n{logits.numpy()}\\n\", sep='')\n",
    "    prob = F.softmax(logits, dim=1)\n",
    "    prob = torch.round(F.softmax(logits, dim=1), decimals = 2)\n",
    "    print(f\"prob = \\n{prob.numpy()}\\n\", sep='')\n",
    "    g_truth = torch.zeros(n_samp).to(torch.int64)\n",
    "    print(f\"ground truth: {g_truth.numpy()}\")\n",
    "    loss = F.cross_entropy(logits, g_truth)\n",
    "    print(f\"loss = {loss.numpy():.5f}\\n\\n======================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = tensor(0.4327)\n",
      "\n",
      "first logits:\n",
      "[[ 1. -1. -1. -1. -1.]\n",
      " [-1.  1. -1. -1. -1.]\n",
      " [-1. -1.  1. -1. -1.]\n",
      " [-1. -1. -1.  1. -1.]\n",
      " [-1. -1. -1. -1.  1.]]\n",
      "\n",
      "loss = tensor(0.0002)\n",
      "loss = tensor(6.6755e-05)\n",
      "loss = tensor(2.4700e-05)\n",
      "loss = tensor(9.0599e-06)\n",
      "loss = tensor(3.3379e-06)\n",
      "last logits:\n",
      "[[13. -1. -1. -1. -1.]\n",
      " [-1. 13. -1. -1. -1.]\n",
      " [-1. -1. 13. -1. -1.]\n",
      " [-1. -1. -1. 13. -1.]\n",
      " [-1. -1. -1. -1. 13.]]\n"
     ]
    }
   ],
   "source": [
    "n_samp = 5\n",
    "g_truth = torch.arange(n_samp)\n",
    "\n",
    "def diag_logits(i):\n",
    "    logits = i*torch.eye(n_samp) - torch.ones(n_samp)\n",
    "    loss = F.cross_entropy(logits, g_truth)\n",
    "    print(f\"{loss = }\")\n",
    "    return logits\n",
    "\n",
    "logits = diag_logits(2)\n",
    "print('\\nfirst logits:\\n', logits.numpy(), '\\n', sep='')\n",
    "\n",
    "for mult in range(10,15):\n",
    "    logits = diag_logits(mult)\n",
    "print('last logits:\\n', logits.numpy(), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = tensor(0.4327)\n",
      "\n",
      "first logits:\n",
      "[[2. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 0.]\n",
      " [0. 0. 2. 0. 0.]\n",
      " [0. 0. 0. 2. 0.]\n",
      " [0. 0. 0. 0. 2.]]\n",
      "\n",
      "loss = tensor(0.0002)\n",
      "loss = tensor(6.6755e-05)\n",
      "loss = tensor(2.4700e-05)\n",
      "loss = tensor(9.0599e-06)\n",
      "loss = tensor(3.3379e-06)\n",
      "last logits:\n",
      "[[14.  0.  0.  0.  0.]\n",
      " [ 0. 14.  0.  0.  0.]\n",
      " [ 0.  0. 14.  0.  0.]\n",
      " [ 0.  0.  0. 14.  0.]\n",
      " [ 0.  0.  0.  0. 14.]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# this gives the same result as adding a scalar to the softmax input doesn't change the outcome\n",
    "#\n",
    "n_samp = 5\n",
    "g_truth = torch.arange(n_samp)\n",
    "\n",
    "def diag_logits(i):\n",
    "    logits = i*torch.eye(n_samp) \n",
    "    loss = F.cross_entropy(logits, g_truth)\n",
    "    print(f\"{loss = }\")\n",
    "    return logits\n",
    "\n",
    "logits = diag_logits(2)\n",
    "print('\\nfirst logits:\\n', logits.numpy(), '\\n', sep='')\n",
    "\n",
    "for mult in range(10,15):\n",
    "    logits = diag_logits(mult)\n",
    "print('last logits:\\n', logits.numpy(), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  1],\n",
      "          [ 2,  3]],\n",
      "\n",
      "         [[ 4,  5],\n",
      "          [ 6,  7]],\n",
      "\n",
      "         [[ 8,  9],\n",
      "          [10, 11]]],\n",
      "\n",
      "\n",
      "        [[[12, 13],\n",
      "          [14, 15]],\n",
      "\n",
      "         [[16, 17],\n",
      "          [18, 19]],\n",
      "\n",
      "         [[20, 21],\n",
      "          [22, 23]]]])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  batch indices!!!\n",
    "#\n",
    "N = 2\n",
    "k = 3\n",
    "d = 2\n",
    "\n",
    "L = torch.arange(N * k * d * d).view(N, 3, 2, 2)\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L[batch_index, index]:\n",
      "[[[ 0  1]\n",
      "  [ 2  3]]\n",
      "\n",
      " [[ 4  5]\n",
      "  [ 6  7]]\n",
      "\n",
      " [[12 13]\n",
      "  [14 15]]\n",
      "\n",
      " [[12 13]\n",
      "  [14 15]]]\n",
      "\n",
      "L[0, 1]:\n",
      "[[4 5]\n",
      " [6 7]]\n"
     ]
    }
   ],
   "source": [
    "index = torch.tensor([0, 1, 0, 0], dtype=torch.long)\n",
    "batch_index = torch.tensor([0, 0, 1, 1])\n",
    "print(f\"L[batch_index, index]:\\n{L[batch_index, index].numpy()}\\n\")\n",
    "print(f\"L[{batch_index[1]}, {index[1]}]:\\n{L[batch_index[1], index[1]].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [1, 1]])\n",
      "tensor([[0, 1],\n",
      "        [0, 1]])\n",
      "tensor([[0, 0, 0, 0],\n",
      "        [1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "index = torch.tensor([0, 1, 0, 0]).view(N, -1)\n",
    "# => tensor([[0, 1],\n",
    "#            [0, 0]])\n",
    "\n",
    "# Every batch gets its index and is repeated across dim=1\n",
    "batch_index = torch.arange(N).view(N, 1).expand_as(index)\n",
    "print(batch_index)\n",
    "# => tensor([[0, 0],\n",
    "#            [1, 1]])\n",
    "# ALSO:\n",
    "#\n",
    "print(torch.arange(N).view(1,N).expand_as(index))\n",
    "#\n",
    "# or:\n",
    "#\n",
    "print(torch.arange(N).view(2,1).expand_as(torch.arange(8).reshape(2,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_index:\n",
      "[[0 1]\n",
      " [0 0]]\n",
      "\n",
      "index:\n",
      "[[0 0]\n",
      " [1 1]]\n",
      "=================================\n",
      "\n",
      "[[[0 1]\n",
      "  [2 3]]\n",
      "\n",
      " [[4 5]\n",
      "  [6 7]]]\n",
      "\n",
      "[[[12 13]\n",
      "  [14 15]]\n",
      "\n",
      " [[12 13]\n",
      "  [14 15]]]\n",
      "\n",
      "\n",
      "=================================\n",
      "\n",
      "[[[[ 0  1]\n",
      "   [ 2  3]]\n",
      "\n",
      "  [[ 4  5]\n",
      "   [ 6  7]]]\n",
      "\n",
      "\n",
      " [[[12 13]\n",
      "   [14 15]]\n",
      "\n",
      "  [[12 13]\n",
      "   [14 15]]]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"batch_index:\\n{index.numpy()}\\n\")\n",
    "print(f\"index:\\n{batch_index.numpy()}\\n=================================\\n\")\n",
    "\n",
    "for b,i in zip(batch_index, index):\n",
    "    print(f\"{L[b,i,:,:].numpy()}\\n\")\n",
    "\n",
    "print(f\"\\n=================================\\n\\n{L[batch_index, index].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.arange(9)\n",
    "t2 = torch.arange(9).reshape(3,3)\n",
    "\n",
    "# because the dimensions are different:\n",
    "print(torch.equal(t1, t2))\n",
    "\n",
    "# views, however are the same (!!)\n",
    "print(torch.equal(t1.view(3,3), t2))\n",
    "\n",
    "# this gives size error:\n",
    "#print(torch.allclose(t1, t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp.std()=tensor(1.0037), inp.mean()=tensor(-0.0031)\n",
      "inp.view(1,-1).std()=tensor(1.0037), inp.mean()=tensor(-0.0031)\n",
      "h.std()=tensor(3.0720), h.mean()=tensor(0.0054)\n",
      "\n",
      "(h - h.mean()).std()=tensor(3.0720)\n",
      "h.view(1,-1).std()=tensor(3.0720)\n",
      "h.view(-1,1).std()=tensor(3.0720)\n",
      "(h - h.mean(dim=1, keepdim=True)).std()=tensor(3.0631)\n",
      "(h - h.mean(dim=0, keepdim=True)).std()=tensor(3.0701)\n",
      "(h - h.mean(dim=0)).std()=tensor(3.0701)\n",
      "\n",
      "h.view(-1,1).mean()=tensor(0.0054)\n",
      "h.mean(dim=0).mean()=tensor(0.0054)\n",
      "h.mean(dim=1).mean()=tensor(0.0054)\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(1)\n",
    "inp = torch.randn(1000, 9, generator=g)\n",
    "w = torch.randn(9, 200, generator=g)\n",
    "\n",
    "h = inp @ w\n",
    "\n",
    "print(f\"{inp.std()=}, {inp.mean()=}\")\n",
    "print(f\"{inp.view(1,-1).std()=}, {inp.mean()=}\")\n",
    "print(f\"{h.std()=}, {h.mean()=}\\n\")\n",
    "\n",
    "print(f\"{(h - h.mean()).std()=}\")\n",
    "print(f\"{h.view(1,-1).std()=}\")\n",
    "print(f\"{h.view(-1,1).std()=}\")\n",
    "print(f\"{(h - h.mean(dim=1, keepdim=True)).std()=}\")\n",
    "print(f\"{(h - h.mean(dim=0, keepdim=True)).std()=}\")\n",
    "print(f\"{(h - h.mean(dim=0)).std()=}\\n\")\n",
    "\n",
    "\n",
    "print(f\"{h.view(-1,1).mean()=}\")\n",
    "print(f\"{h.mean(dim=0).mean()=}\")\n",
    "print(f\"{h.mean(dim=1).mean()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.951111793518066\n",
      "9.951111793518066\n",
      "9.951111793518066\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(1)\n",
    "inp = torch.randn(100, 90, generator=g)\n",
    "w = torch.randn(90, 20, generator=g)\n",
    "\n",
    "h = inp @ w\n",
    "\n",
    "print(f\"{h.std()}\")\n",
    "print(f\"{h.view(1,-1).std()}\")\n",
    "print(f\"{h.view(-1,1).std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp.std()=tensor(1.0196), inp.mean()=tensor(0.0216)\n",
      "h.std()=tensor(3.1137), h.mean()=tensor(0.0078)\n",
      "\n",
      "(h - h.mean()).std()=tensor(3.1137)\n",
      "h.view(1,-1).std()=tensor(3.1137)\n",
      "h.view(-1,1).std()=tensor(3.1137)\n",
      "(h - h.mean(dim=1, keepdim=True)).std()=tensor(3.1103)\n",
      "(h - h.mean(dim=0, keepdim=True)).std()=tensor(3.0867)\n",
      "(h - h.mean(dim=0)).std()=tensor(3.0867)\n",
      "\n",
      "h.view(-1,1).mean()=tensor(0.0078)\n",
      "h.mean(dim=0).mean()=tensor(0.0078)\n",
      "h.mean(dim=1).mean()=tensor(0.0078)\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(1)\n",
    "inp = torch.randn(100, 9, generator=g)\n",
    "w = torch.randn(9, 200, generator=g)\n",
    "\n",
    "h = inp @ w\n",
    "\n",
    "print(f\"{inp.std()=}, {inp.mean()=}\")\n",
    "print(f\"{h.std()=}, {h.mean()=}\\n\")\n",
    "\n",
    "print(f\"{(h - h.mean()).std()=}\")\n",
    "print(f\"{h.view(1,-1).std()=}\")\n",
    "print(f\"{h.view(-1,1).std()=}\")\n",
    "print(f\"{(h - h.mean(dim=1, keepdim=True)).std()=}\")\n",
    "print(f\"{(h - h.mean(dim=0, keepdim=True)).std()=}\")\n",
    "print(f\"{(h - h.mean(dim=0)).std()=}\\n\")\n",
    "\n",
    "\n",
    "print(f\"{h.view(-1,1).mean()=}\")\n",
    "print(f\"{h.mean(dim=0).mean()=}\")\n",
    "print(f\"{h.mean(dim=1).mean()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor(0.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# randn(Nsamples, shape) (Gaussian random) \n",
    "#     is equivalent to a bunch of Gaussian samples of dim 1xN (N is \"size\" of shape (product of shape components))\n",
    "#\n",
    "g = torch.Generator().manual_seed(1)\n",
    "inp1 = torch.randn(1000, 9, generator=g)\n",
    "\n",
    "g = torch.Generator().manual_seed(1)\n",
    "inp2 = torch.randn(9000, generator=g)\n",
    "\n",
    "print(torch.allclose(inp1.view(1,-1), inp2))\n",
    "print(torch.max((inp1.view(1,-1) - inp2).abs()))\n",
    "torch.equal(inp1.reshape(9000), inp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
