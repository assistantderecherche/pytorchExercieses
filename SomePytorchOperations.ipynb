{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zeQOHsYkBCwx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-XjhuYKBIj8",
    "outputId": "d3ab2132-5f32-45d1-9d6c-17b90212cc4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]]\n",
      "\n",
      " [[ 9 10 11]\n",
      "  [12 13 14]\n",
      "  [15 16 17]]\n",
      "\n",
      " [[18 19 20]\n",
      "  [21 22 23]\n",
      "  [24 25 26]]] \n",
      "\n",
      "manually compute sum() on the first dimension:\n",
      "[[27. 30. 33.]\n",
      " [36. 39. 42.]\n",
      " [45. 48. 51.]]\n",
      "\n",
      "torch.sum(,0):\n",
      "[[27 30 33]\n",
      " [36 39 42]\n",
      " [45 48 51]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  sum on the first dim, not keeping dimensionality\n",
    "#\n",
    "\n",
    "aa = torch.tensor(range(27)).reshape(3,3,3)\n",
    "ss = torch.zeros(3,3)\n",
    "print(aa.numpy(),'\\n')\n",
    "for j in range(3):\n",
    "    for k in range(3):\n",
    "        ss[j,k] = torch.sum(aa[:, j, k])\n",
    "print(f\"manually compute sum() on the first dimension:\\n{ss.numpy()}\\n\")\n",
    "print(f\"torch.sum(,0):\\n{torch.sum(aa, 0).numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vU7aAgfZBLXB",
    "outputId": "ff70ef60-ac5f-422a-dc51-a7e6df1fd9f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]]\n",
      "\n",
      " [[ 9 10 11]\n",
      "  [12 13 14]\n",
      "  [15 16 17]]\n",
      "\n",
      " [[18 19 20]\n",
      "  [21 22 23]\n",
      "  [24 25 26]]] \n",
      "\n",
      "manually compute sum() on the first dimension:\n",
      "[[[ 9. 12. 15.]]\n",
      "\n",
      " [[36. 39. 42.]]\n",
      "\n",
      " [[63. 66. 69.]]]\n",
      "\n",
      "torch.sum(,1):\n",
      "[[[ 9 12 15]]\n",
      "\n",
      " [[36 39 42]]\n",
      "\n",
      " [[63 66 69]]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  sum on the second dim, keeping dimensionality\n",
    "#\n",
    "\n",
    "aa = torch.tensor(range(27)).reshape(3,3,3)\n",
    "ss = torch.zeros(3,3).reshape(3,1,3)\n",
    "print(aa.numpy(),'\\n')\n",
    "for i in range(3):\n",
    "    for k in range(3):\n",
    "        ss[i,0,k] = torch.sum(aa[i,:, k])\n",
    "print(f\"manually compute sum() on the first dimension:\\n{ss.numpy()}\\n\")\n",
    "print(f\"torch.sum(,1):\\n{torch.sum(aa, 1, keepdim=True).numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1NDDcLIDBRv0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "[[1. 0. 0.]\n",
      " [1. 1. 0.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "torch.sum(a, 1, keepdim=True).shape: torch.Size([3, 1])\n",
      "torch.sum(a, 1, keepdim=True:\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "This is sum over rows as expected\n",
      "\n",
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "print(f\"a=\\n{a.numpy()}\\n\")\n",
    "print(f\"torch.sum(a, 1, keepdim=True).shape: {torch.sum(a, 1, keepdim=True).shape}\")\n",
    "print(f\"torch.sum(a, 1, keepdim=True:\\n{torch.sum(a, 1, keepdim=True)}\")\n",
    "print(\"This is sum over rows as expected\\n\")\n",
    "\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: broadcasting at work!\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]]) \n",
      "\n",
      "SAME as if div = \n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3],\n",
      "        [4, 4, 4, 4]])\n",
      "\n",
      "wei/div =\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]])\n",
      "\n",
      "SAME result if div1 = tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "\n",
      "wei/div1 = tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]])\n",
      "\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]]) \n",
      "\n",
      "COMPARE: tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.5000, 0.0000, 0.0000],\n",
      "        [1.0000, 0.5000, 0.3333, 0.0000],\n",
      "        [1.0000, 0.5000, 0.3333, 0.2500]])\n",
      "\n",
      "torch.sum(wei, dim=1, keepdim=True) =\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]])\n",
      "\n",
      "torch.sum(wei, dim=1, keepdim=True).shape = torch.Size([4, 1])\n",
      "\n",
      "torch.sum(wei, dim=1, keepdim=False) =\n",
      "tensor([1., 2., 3., 4.])\n",
      "\n",
      "torch.sum(wei, dim=1, keepdim=False).shape = torch.Size([4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "B,T,C = 4,4,4\n",
    "\n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei_keepdim = wei/torch.sum(wei, dim=1, keepdim=True)\n",
    "wei_no_keepdim = wei/torch.sum(wei, dim=1)\n",
    "\n",
    "print(\"IMPORTANT: broadcasting at work!\")\n",
    "print(wei_keepdim, '\\n')\n",
    "div = torch.tensor([[1,1,1,1], [2,2,2,2], [3,3,3,3], [4,4,4,4]])\n",
    "print(f\"SAME as if div = \\n{div}\\n\")\n",
    "print(f\"wei/div =\\n{wei/div}\\n\")\n",
    "div1=torch.tensor([[1,2,3,4]]).reshape(4,1)\n",
    "print(f\"SAME result if div1 = {div1}\\n\")\n",
    "print(f\"wei/div1 = {wei/div1}\\n\")\n",
    "print(wei/div, '\\n')\n",
    "print(f\"COMPARE: {wei_no_keepdim}\\n\")\n",
    "\n",
    "print(f\"torch.sum(wei, dim=1, keepdim=True) =\\n{torch.sum(wei, dim=1, keepdim=True)}\\n\")\n",
    "print(f\"torch.sum(wei, dim=1, keepdim=True).shape = {torch.sum(wei, dim=1, keepdim=True).shape}\\n\")\n",
    "\n",
    "print(f\"torch.sum(wei, dim=1, keepdim=False) =\\n{torch.sum(wei, dim=1, keepdim=False)}\\n\")\n",
    "print(f\"torch.sum(wei, dim=1, keepdim=False).shape = {torch.sum(wei, dim=1, keepdim=False).shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "div = torch.tensor([[1,1,1,1], [2,2,2,2], [3,3,3,3], [4,4,4,4]])\n",
    "print(wei/div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the actual matrix multiplication: a*b = \n",
      "[[ 7 10]\n",
      " [15 22]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a=np.matrix([[1, 2], [3, 4]])\n",
    "b=np.matrix([[1, 2], [3, 4]])\n",
    "\n",
    "print(f\"\\nThis is the actual matrix multiplication: a*b = \\n{a*b}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is element-wise multiplication a.b =\n",
      "[[ 1  4]\n",
      " [ 9 16]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[1, 2], [3, 4]])\n",
    "print(f\"This is element-wise multiplication a.b =\\n{(a*b).numpy()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Pytorch matrix multiplication a@b =\n",
      "[[ 7 10]\n",
      " [15 22]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[1, 2], [3, 4]])\n",
    "print(f\"This is Pytorch matrix multiplication a@b =\\n{(a@b).numpy()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = torch.Size([4, 3, 3])\n",
      "wei.shape = torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "B,T,C = 4,3,3\n",
    "\n",
    "x = torch.randn(B,T,C)\n",
    "print(f\"x.shape = {x.shape}\")\n",
    "\n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei/torch.sum(wei, 1, keepdim=True)\n",
    "print(f\"wei.shape = {wei.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broadcasted on the first argument wei shape: torch.Size([4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "br = torch.tensor([])\n",
    "w = torch.unsqueeze(wei, dim=0)\n",
    "for b in range(B):\n",
    "    br = torch.cat((br,w),0)\n",
    "print(f\"broadcasted on the first argument wei shape: {br.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1=wei @ x\n",
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2=w @ x\n",
    "w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOATING ERROR .... \n",
      "w1 - w2 =\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 1.1921e-07, 1.3039e-08]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"FLOATING ERROR .... \\nw1 - w2 =\\n{w1 - w2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOATING ERROR .... \n",
      "w1 == w2:\n",
      "tensor([[[ True,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True, False, False]],\n",
      "\n",
      "        [[ True,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True,  True]],\n",
      "\n",
      "        [[ True,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True,  True]],\n",
      "\n",
      "        [[ True,  True,  True],\n",
      "         [ True,  True,  True],\n",
      "         [ True,  True,  True]]])\n",
      "\n",
      "But they are close: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"FLOATING ERROR .... \\nw1 == w2:\\n{w1 == w2}\\n\")\n",
    "print(f\"But they are close: {torch.allclose(w1,w2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Works just fine with integer-valued tensors:\n",
      "torch.equal(w @ x, wei @ x): True\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(100, (B,T,C))\n",
    "wei = torch.randint(100, (T,T))\n",
    "w = torch.unsqueeze(wei,0)\n",
    "print(f\"Works just fine with integer-valued tensors:\\ntorch.equal(w @ x, wei @ x): {torch.equal(w @ x, wei @ x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0.]])\n",
      "\n",
      "F.softmax(x, dim=0) = \n",
      "tensor([[0.3333, 0.1554, 0.2119, 0.3333],\n",
      "        [0.3333, 0.4223, 0.2119, 0.3333],\n",
      "        [0.3333, 0.4223, 0.5761, 0.3333]])\n",
      "\n",
      "Same assembled per column (dim=0):\n",
      "tensor([[0.3333, 0.1554, 0.2119, 0.3333],\n",
      "        [0.3333, 0.4223, 0.2119, 0.3333],\n",
      "        [0.3333, 0.4223, 0.5761, 0.3333]])\n"
     ]
    }
   ],
   "source": [
    "#x = torch.tensor(range(12)).reshape(3,4).to(torch.float64)\n",
    "x = torch.tril(torch.ones(3,4))\n",
    "print(f\"data:\\n{x}\\n\")\n",
    "\n",
    "print(f\"F.softmax(x, dim=0) = \\n{F.softmax(x, dim=0)}\\n\")\n",
    "\n",
    "res = []\n",
    "for j in range(x.shape[1]):\n",
    "    c = x[:,j]\n",
    "#     print(c)\n",
    "#     print(F.softmax(c, dim=0).T, '\\n')\n",
    "    res.append(F.softmax(c, dim=0))\n",
    "\n",
    "r = torch.stack(res, 1)\n",
    "print(f\"Same assembled per column (dim=0):\\n{r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0.]])\n",
      "\n",
      "F.softmax(x, dim=1) = \n",
      "tensor([[0.4754, 0.1749, 0.1749, 0.1749],\n",
      "        [0.3655, 0.3655, 0.1345, 0.1345],\n",
      "        [0.2969, 0.2969, 0.2969, 0.1092]])\n",
      "\n",
      "Same assembled per row (dim=1):\n",
      "tensor([[0.4754, 0.1749, 0.1749, 0.1749],\n",
      "        [0.3655, 0.3655, 0.1345, 0.1345],\n",
      "        [0.2969, 0.2969, 0.2969, 0.1092]])\n"
     ]
    }
   ],
   "source": [
    "#x = torch.tensor(range(12)).reshape(3,4).to(torch.float64)\n",
    "x = torch.tril(torch.ones(3,4))\n",
    "print(f\"data:\\n{x}\\n\")\n",
    "\n",
    "print(f\"F.softmax(x, dim=1) = \\n{F.softmax(x, dim=1)}\\n\")\n",
    "\n",
    "res = []\n",
    "for i in range(x.shape[0]):\n",
    "    c = x[i,:]\n",
    "#     print(c)\n",
    "#     print(F.softmax(c, dim=0).T, '\\n')\n",
    "    res.append(F.softmax(c, dim=0))\n",
    "\n",
    "r = torch.stack(res, 0)\n",
    "print(f\"Same assembled per row (dim=1):\\n{r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor(range(9)).reshape(3,3)\n",
    "print(t)\n",
    "\n",
    "indices = torch.tensor([0,2])\n",
    "\n",
    "torch.index_select(t, 0, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11],\n",
      "         [12, 13, 14],\n",
      "         [15, 16, 17]],\n",
      "\n",
      "        [[18, 19, 20],\n",
      "         [21, 22, 23],\n",
      "         [24, 25, 26]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2],\n",
       "         [ 6,  7,  8]],\n",
       "\n",
       "        [[ 9, 10, 11],\n",
       "         [15, 16, 17]],\n",
       "\n",
       "        [[18, 19, 20],\n",
       "         [24, 25, 26]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor(range(27)).reshape(3,3,3)\n",
    "print(t)\n",
    "\n",
    "indices = torch.tensor([0,2])\n",
    "\n",
    "torch.index_select(t, 1, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      "tensor([[ 1.,  0.,  0.],\n",
      "        [ 1.,  1.,  0.],\n",
      "        [ 1.,  1., 10.]])\n",
      "\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([ 0.,  0., 10.]) \n",
      "\n",
      "sum(..,0):\n",
      "tensor([ 3.,  2., 10.])\n",
      "\n",
      "----------------------\n",
      "\n",
      "sum(..,1):\n",
      "tensor([ 1.,  2., 12.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# sum: checking the obvious\n",
    "#\n",
    "\n",
    "a  = torch.tril(torch.ones(3,3))\n",
    "a[2,2] = 10\n",
    "print(f\"original:\\n{a}\\n\")\n",
    "\n",
    "\n",
    "print(a[:,0])\n",
    "print(a[:,1])\n",
    "print(a[:,2],'\\n')\n",
    "print(f\"sum(..,0):\\n{torch.sum(a, 0)}\\n\\n----------------------\\n\")\n",
    "\n",
    "print(f\"sum(..,1):\\n{torch.sum(a, 1)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      "tensor([[[ 1.,  0.,  0.],\n",
      "         [ 1.,  1.,  0.],\n",
      "         [ 1.,  1.,  1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 1.,  1.,  0.],\n",
      "         [ 1.,  1.,  1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 1.,  1.,  0.],\n",
      "         [ 1.,  1., 10.]]])\n",
      "\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([ 1.,  1., 10.])\n",
      "sum(..,0):\n",
      "tensor([[ 3.,  0.,  0.],\n",
      "        [ 3.,  3.,  0.],\n",
      "        [ 3.,  3., 12.]])\n",
      "\n",
      "----------------------\n",
      "\n",
      "sum(..,1):\n",
      "tensor([[ 3.,  2.,  1.],\n",
      "        [ 3.,  2.,  1.],\n",
      "        [ 3.,  2., 10.]])\n",
      "\n",
      "sum(..,2):\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 1.,  2.,  3.],\n",
      "        [ 1.,  2., 12.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# sum: checking the obvious\n",
    "#\n",
    "\n",
    "a  = torch.tril(torch.ones(3,3,3))\n",
    "a[2,2,2] = 10\n",
    "print(f\"original:\\n{a}\\n\")\n",
    "\n",
    "print(a[:,0,0])\n",
    "print(a[:,0,1])\n",
    "print(a[:,0,2])\n",
    "print(a[:,1,0])\n",
    "print(a[:,1,1])\n",
    "print(a[:,2,2])\n",
    "print(f\"sum(..,0):\\n{torch.sum(a, 0)}\\n\\n----------------------\\n\")\n",
    "\n",
    "print(f\"sum(..,1):\\n{torch.sum(a, 1)}\\n\")\n",
    "print(f\"sum(..,2):\\n{torch.sum(a, 2)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wei =\n",
      "tensor([[0, 1, 1, 1, 1],\n",
      "        [1, 0, 1, 1, 1],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [1, 1, 1, 0, 1],\n",
      "        [1, 1, 1, 1, 0]], dtype=torch.int16)\n",
      "\n",
      "t =\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]])\n",
      "\n",
      "\n",
      "For example:\n",
      "\n",
      "t*wei =\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  0,  7,  8,  9],\n",
      "        [10, 11,  0, 13, 14],\n",
      "        [15, 16, 17,  0, 19],\n",
      "        [20, 21, 22, 23,  0]])\n"
     ]
    }
   ],
   "source": [
    "# Diagonal operation:\n",
    "T=5\n",
    "wei =torch.tril(torch.ones(T,T), diagonal=-1).to(torch.int16) + \\\n",
    "    torch.tril(torch.ones(T,T), diagonal=-1).mT.to(torch.int16)\n",
    "print(f\"wei =\\n{wei}\\n\")\n",
    "print(f\"t =\\n{t}\\n\")\n",
    "print('\\nFor example:\\n')\n",
    "\n",
    "t = torch.tensor(range(T**2)).reshape(T,T)\n",
    "\n",
    "print(f\"t*wei =\\n{t*wei}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0])\n",
      "torch.Size([2, 2])\n",
      "tensor([[3.5927e+34, 3.0872e-41],\n",
      "        [3.8682e+34, 3.0872e-41]])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# perhaps this is faster as it doesn't need to be initialized in comparison with\n",
    "# torch.zeros((2,2))\n",
    "#\n",
    "e = torch.empty((0,))\n",
    "print(e.shape)\n",
    "e1 = torch.empty((2,2))\n",
    "print(e1.shape)\n",
    "print(e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 8, 9, 2])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Apparently broadcasting to more than 1 dimension works just fine\n",
    "#    all that's required is that the data can be expanded without\n",
    "#    copying the data\n",
    "#\n",
    "\n",
    "a=torch.ones(    8,1,2)\n",
    "b=torch.ones(2,4,8,9,1)\n",
    "\n",
    "(a+b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]])\n",
      "\n",
      "VS\n",
      "\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]])\n",
      "\n",
      "wei == wei1: True\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Not sure what's the advantage of using masked_fill vs just [condition] operation:\n",
    "#\n",
    "T=5\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros(T,T)\n",
    "wei[tril == 0] = float('-inf')\n",
    "wei = torch.softmax(wei, dim=1)\n",
    "print(wei)\n",
    "\n",
    "print('\\nVS\\n')\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei1 = torch.zeros(T,T)\n",
    "wei1 = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei1 = torch.softmax(wei1, dim=1)\n",
    "print(wei1)\n",
    "\n",
    "print(f\"\\nwei == wei1: {torch.allclose(wei1, wei)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'b', 'c')\n",
      "[('a', 'b'), 'c']\n",
      "['a', 'b', 'c']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Tuples are immutable, of course\n",
    "#    some syntax picularities:\n",
    "#\n",
    "a=('a','b')\n",
    "b=('c')\n",
    "c=tuple(list(a)+list(b))\n",
    "print(c)\n",
    "\n",
    "# somehow things like\n",
    "c=([a]+[b])\n",
    "print(c)\n",
    "# or even\n",
    "c=(list(a)+list(b))\n",
    "print(c)\n",
    "#don't work\n",
    "\n",
    "# it looks like one has to use 'list' and 'tuple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
